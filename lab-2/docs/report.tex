\documentclass[12pt,a4paper]{article}

% Essential packages
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{listings}
\usepackage[table]{xcolor}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{enumitem}
\usepackage{float}
\usepackage{enumitem}

% Additional packages for beautification
\usepackage[skins,breakable,raster]{tcolorbox}
\usepackage{fontspec}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{tikz}
\usepackage{pifont}  % For checkmarks and symbols
\usepackage{fontawesome5}  % Modern icons
\usepackage{colortbl}

\usetikzlibrary{shadows.blur,positioning,calc,decorations.pathmorphing}

\usepackage{array}
\setlength{\tabcolsep}{8pt}

% ============================================
% MODERN COLOR PALETTE
% ============================================
\definecolor{primaryBlue}{RGB}{26,54,93}        % Deep navy
\definecolor{accentBlue}{RGB}{59,130,246}       % Bright blue
\definecolor{secondaryTeal}{RGB}{20,184,166}    % Teal accent
\definecolor{warningOrange}{RGB}{249,115,22}    % Orange
\definecolor{successGreen}{RGB}{34,197,94}      % Green
\definecolor{dangerRed}{RGB}{239,68,68}         % Red
\definecolor{purpleAccent}{RGB}{139,92,246}     % Purple
\definecolor{lightBlueBg}{RGB}{239,246,255}     % Light blue bg
\definecolor{lightTealBg}{RGB}{240,253,250}     % Light teal bg
\definecolor{lightPurpleBg}{RGB}{250,245,255}   % Light purple bg
\definecolor{codeGray}{RGB}{249,250,251}        % Code background
\definecolor{borderGray}{RGB}{226,232,240}      % Border color
\definecolor{textDark}{RGB}{30,41,59}           % Dark text
\definecolor{textMuted}{RGB}{100,116,139}       % Muted text

% ============================================
% HYPERLINK STYLING
% ============================================
\hypersetup{
    colorlinks=true,
    linkcolor=accentBlue,
    filecolor=accentBlue,
    urlcolor=accentBlue,
    citecolor=accentBlue
}

% ============================================
% CUSTOM TCOLORBOX STYLES - MODERN DESIGN
% ============================================

% Main content box with shadow
\tcbset{
    mybox/.style={
        enhanced,
        colback=lightBlueBg,
        colframe=accentBlue,
        arc=4mm,
        boxrule=1pt,
        left=4mm,
        right=4mm,
        top=3mm,
        bottom=3mm,
        drop shadow={shadow xshift=0.5mm, shadow yshift=-0.5mm, opacity=0.15}
    }
}

% Titled box with gradient-like header
\newtcolorbox{mytitledbox}[1]{
    enhanced,
    colback=white,
    colframe=primaryBlue,
    arc=4mm,
    boxrule=1.2pt,
    title={\faChartBar\hspace{2mm}\textbf{#1}},
    coltitle=white,
    fonttitle=\bfseries\sffamily,
    colbacktitle=primaryBlue,
    attach boxed title to top left={yshift=-2mm, xshift=4mm},
    boxed title style={arc=2mm, boxrule=0pt},
    top=3mm,
    drop shadow={shadow xshift=0.5mm, shadow yshift=-0.5mm, opacity=0.12}
}

% Solution/Analysis box with left accent bar
\newtcolorbox{solutionbox}{
    enhanced,
    colback=lightBlueBg,
    colframe=borderGray,
    arc=2mm,
    boxrule=0.5pt,
    borderline west={3pt}{0pt}{accentBlue},
    left=6mm,
    right=4mm,
    top=3mm,
    bottom=3mm,
    before=\vspace{3mm},
    after=\vspace{3mm},
    breakable
}

% Version boxes with modern styling
\newtcolorbox{versionbox}[1]{
    enhanced,
colback=lightPurpleBg,
colframe=purpleAccent,
colbacktitle=purpleAccent,
    arc=4mm,
    boxrule=1pt,
    title={\faMicrochip\hspace{2mm}\textbf{#1}},
    coltitle=white,
    fonttitle=\bfseries\sffamily,
    attach boxed title to top left={yshift=-2mm, xshift=4mm},
    boxed title style={arc=2mm, boxrule=0pt},
    top=6mm,
    left=4mm,
    right=4mm,
    bottom=3mm,
    drop shadow={shadow xshift=0.5mm, shadow yshift=-0.5mm, opacity=0.12}
}

% Info box (blue)
\newtcolorbox{infobox}{
    enhanced,
    colback=lightBlueBg,
    colframe=accentBlue,
    arc=3mm,
    boxrule=0.8pt,
    borderline west={3pt}{0pt}{accentBlue},
    left=6mm,
    before skip=4mm,
    after skip=4mm
}

% Tip box (green)
\newtcolorbox{tipbox}{
    enhanced,
    colback=lightTealBg,
    colframe=secondaryTeal,
    arc=3mm,
    boxrule=0.8pt,
    borderline west={3pt}{0pt}{successGreen},
    left=6mm,
    before skip=4mm,
    after skip=4mm
}

% Warning box (orange)
\newtcolorbox{warningbox}{
    enhanced,
    colback=lightOrangeBg,
    colframe=warningOrange,
    arc=3mm,
    boxrule=0.8pt,
    borderline west={3pt}{0pt}{warningOrange},
    left=6mm,
    before skip=4mm,
    after skip=4mm
}

% ============================================
% HEADER AND FOOTER SETUP
% ============================================
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{1.2pt}
\renewcommand{\headrule}{\hbox to\headwidth{\color{primaryBlue}\leaders\hrule height \headrulewidth\hfill}}
\renewcommand{\footrulewidth}{0.4pt}
\renewcommand{\footrule}{\hbox to\headwidth{\color{borderGray}\leaders\hrule height \footrulewidth\hfill}}
\fancyhead[L]{\sffamily\textcolor{primaryBlue}{\faMicrochip\hspace{2mm}Computer Architecture Laboratory}}
\fancyhead[R]{\sffamily\textcolor{primaryBlue}{Lab 2 Report\hspace{2mm}\faFlask}}
\fancyfoot[C]{\sffamily\textcolor{textMuted}{\thepage}}
\setlength{\headheight}{16pt}
\addtolength{\topmargin}{-2.5pt}

% ============================================
% SECTION STYLING WITH DECORATIONS
% ============================================
\usepackage{titlesec}

\titleformat{\section}
  {\normalfont\Large\bfseries\sffamily\color{primaryBlue}}
  {\colorbox{primaryBlue}{\textcolor{white}{\thesection}}}{0.8em}{}[{\color{primaryBlue}\titlerule[1.5pt]}]
\titlespacing*{\section}{0pt}{12pt plus 4pt minus 2pt}{8pt plus 2pt minus 2pt}

\titleformat{\subsection}
  {\normalfont\large\bfseries\sffamily\color{primaryBlue}}
  {\textcolor{accentBlue}{\thesubsection}}{0.8em}{}[]
\titlespacing*{\subsection}{0pt}{10pt plus 4pt minus 2pt}{6pt plus 2pt minus 2pt}

\titleformat{\subsubsection}
  {\normalfont\normalsize\bfseries\sffamily\color{primaryBlue}}
  {\textcolor{secondaryTeal}{\thesubsubsection}}{0.8em}{}

% ============================================
% CODE LISTING STYLE - MODERN
% ============================================
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{codeGray},
    commentstyle=\color{successGreen}\itshape,
    keywordstyle=\color{accentBlue}\bfseries,
    numberstyle=\tiny\color{textMuted}\sffamily,
    stringstyle=\color{purpleAccent},
    basicstyle=\ttfamily\small,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=8pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single,
    framesep=6pt,
    framerule=0.8pt,
    rulecolor=\color{borderGray},
    framexleftmargin=8pt,
    framexrightmargin=6pt,
    framextopmargin=5pt,
    framexbottommargin=5pt,
    xleftmargin=12pt,
    xrightmargin=6pt,
}
\lstset{style=mystyle}

% ============================================
% CUSTOM COMMANDS FOR ICONS AND STYLING
% ============================================
\newcommand{\mycheck}{\textcolor{successGreen}{\ding{51}}}
\newcommand{\mycross}{\textcolor{dangerRed}{\ding{55}}}
\newcommand{\promark}{\textcolor{successGreen}{$+$}}
\newcommand{\conmark}{\textcolor{dangerRed}{$-$}}
\newcommand{\bulletpoint}{\textcolor{accentBlue}{\faAngleRight}}
\newcommand{\highlight}[1]{\colorbox{lightBlueBg}{\textcolor{primaryBlue}{\textbf{#1}}}}

% Custom table column types
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}}

% ==========================================
% TITLE PAGE
% ==========================================

\title{
    \vspace*{1.5cm}
    {\fontsize{42}{50}\selectfont\bfseries\sffamily\textcolor{primaryBlue}{Computer Architecture}}\\[0.3cm]
    {\fontsize{28}{36}\selectfont\sffamily\textcolor{accentBlue}{Laboratory Report}}\\[1.2cm]
    {\color{primaryBlue}\rule{0.8\textwidth}{2pt}}\\[0.8cm]
    {\LARGE\sffamily\textcolor{textDark}{Lab 2: Image Processing Accelerator}}\\[0.3cm]
    {\Large\sffamily\textcolor{textMuted}{with Sharpening Filter}}\\[1.5cm]
    \fbox{\parbox{0.4\textwidth}{\centering
        \vspace{3mm}
        {\large\sffamily\textcolor{textMuted}{Author}}\\[3mm]
        {\Large\bfseries\sffamily\textcolor{primaryBlue}{Fraidakis Ioannis}}
        \vspace{3mm}
    }}\\[2cm]
    {\color{borderGray}\rule{0.3\textwidth}{1pt}}
}
\author{}
\date{{\Large\sffamily\textcolor{textMuted}{December 2025}}}

\begin{document}
\maketitle

\newpage

\section{Introduction}

\begin{tcolorbox}[mybox]
\faLaptopCode\hspace{2mm}This laboratory exercise extends the previous lab by adding a 3×3 sharpening filter to the image processing pipeline. The accelerator now performs three operations in sequence:
\begin{enumerate}[label=\textcolor{accentBlue}{\arabic*.}, itemsep=2mm, leftmargin=6mm]
    \item \textbf{Absolute Difference}: $D[i][j] = |A[i][j] - B[i][j]|$
    \item \textbf{Posterization}: Map $D$ to discrete levels (0, 128, or 255)
    \item \textbf{Sharpen Filter}: Apply a Laplacian-based 3×3 convolution kernel
\end{enumerate}

\vspace{2mm}
\textcolor{textMuted}{\faInfoCircle}\hspace{2mm}\textit{Additionally, three different architectural implementations (V1, V2, V3) were developed to explore optimization strategies for throughput and resource utilization, analyzing trade-offs between memory access patterns and dataflow parallelism.}
\end{tcolorbox}

\section{Algorithm Description}

\subsection{Processing Pipeline}

The image processing pipeline consists of three stages:

\begin{enumerate}
    \item \textbf{Difference Calculation:} For each pixel $(i, j)$:
    $$D[i][j] = |A[i][j] - B[i][j]|$$
    
    \item \textbf{Posterization Thresholding:} 
    $$
    P[i][j] = 
    \begin{cases} 
    0 & \text{if } D < 32 \quad (\text{Black}) \\
    128 & \text{if } 32 \le D < 96 \quad (\text{Gray}) \\
    255 & \text{if } D \ge 96 \quad (\text{White})
    \end{cases}
    $$
    
    \item \textbf{Sharpen Filter:} Apply Laplacian-based 3×3 kernel:
    $$
    K = \begin{bmatrix}
    0 & -1 & 0 \\
    -1 & 5 & -1 \\
    0 & -1 & 0
    \end{bmatrix}
    $$
    The convolution output is computed as:
    $$C[i][j] = 5 \cdot P[i][j] - P[i-1][j] - P[i+1][j] - P[i][j-1] - P[i][j+1]$$
    The result is then clamped to the valid pixel range:
    $$C[i][j] = \min(255, \max(0, C[i][j]))$$
\end{enumerate}

\subsection{Memory Interface}

All implementations use 512-bit wide AXI master interfaces (64 pixels per memory transaction). This aligns with the DDR memory bus width and maximizes memory bandwidth utilization, enabling efficient burst transfers to and from global memory.

\section{Implementation Versions}

\vspace{2mm}
This section describes the three accelerator implementations and architectural differences.
% \vspace{1mm}

\begin{versionbox}{Version 1: Sequential Three-Stage Pipeline}
\textbf{\faFile*[regular]\hspace{2mm}File:} \texttt{src\_hw/accelerated\_v1.cpp}

\vspace{4mm}

\textbf{\faCubes\hspace{2mm}Architecture Overview:}
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, itemsep=1.5mm, leftmargin=5mm]
    \item Three sequential stages that execute one after another
    \item Uses 2D local BRAM buffers (\texttt{C\_tmp[HEIGHT][PADDED\_WIDTH]}, \texttt{C\_filt})
    \item Full-frame buffering (entire image stored in on-chip memory)
    % \item Separate AXI bundles (\texttt{gmemA}, \texttt{gmemB}, \texttt{gmemC}) enable concurrent DDR access
\end{itemize}

\textbf{\faLayerGroup\hspace{2mm}Stage Execution:}
\begin{enumerate}[label=\textcolor{warningOrange}{\arabic*.}, itemsep=1.5mm, leftmargin=6mm]
    \item \textbf{Stage 1 (Posterize):} Read 512-bit chunks from A/B, compute absolute difference, apply posterization (3-level quantization), store results to \texttt{C\_tmp} buffer
    \item \textbf{Stage 2 (Filter):} \underline{Pixel-by-pixel} filtering with direct 2D array access
    \item \textbf{Stage 3 (Pack):} Read from \texttt{C\_filt}, pack into 512-bit words, write to DDR
\end{enumerate}

\textbf{\faChartLine\hspace{2mm}Throughput Analysis:}
\begin{itemize}[label=\textcolor{primaryBlue}{\faCircle[regular]}, itemsep=1mm, leftmargin=5mm]
    \item \textbf{Stage 1 \& 3:} Process 64 pixels/cycle (limited by 512-bit memory interface)
    \item \textbf{Stage 2:} Processes only 1 pixel/cycle  --- \textit{this is the performance bottleneck}
    \item \textbf{Total Latency:} $\approx$ \texttt{TOTAL\_CHUNKS} + \texttt{HEIGHT} $\times$ \texttt{WIDTH} + \texttt{TOTAL\_CHUNKS} cycles
\end{itemize}

\textbf{\faCogs\hspace{2mm}Key Optimizations:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item \texttt{\#pragma HLS ARRAY\_PARTITION variable=C\_tmp cyclic factor=3 dim=1}\\ {\small\textcolor{textMuted}{Enables parallel access to north/center/south rows in Filter stage}}
    \item \texttt{\#pragma HLS ARRAY\_PARTITION variable=C\_tmp cyclic factor=64 dim=2}\\ {\small\textcolor{textMuted}{Enables 64-pixel parallel access in Posterize stage}}
    \item \texttt{\#pragma HLS PIPELINE II=1} on all major loops
    \item \texttt{\#pragma HLS UNROLL} for inner 64-pixel processing
\end{itemize}

\textbf{\faBalanceScale\hspace{2mm}Trade-offs:}
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item[\textcolor{successGreen}{\faCheckCircle}] Simple to implement and debug --- good starting point and reference baseline
    \item[\textcolor{successGreen}{\faCheckCircle}] Pixel-by-pixel filtering avoids line buffer complexity (unlike V2/V3)
    \item[\textcolor{dangerRed}{\faTimesCircle}] Requires substantial BRAM for full-frame buffering
    \item[\textcolor{dangerRed}{\faTimesCircle}] Stages execute sequentially (no overlap)
\end{itemize}
\end{versionbox}

\newpage

\begin{versionbox}{Version 2: Sequential with Line Buffers}
\textbf{\faFile*[regular]\hspace{2mm}File:} \texttt{src\_hw/accelerated\_v2.cpp}

\vspace{4mm}

\textbf{\faCubes\hspace{2mm}Architecture Overview:}
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, itemsep=1.5mm, leftmargin=5mm]
    \item Three sequential stages (same as V1) but with optimized filter stage
    \item Uses 1D packed 512-bit chunk buffers (\texttt{uint512\_t C\_tmp[TOTAL\_CHUNKS]}) instead of V1's 2D pixel arrays
    \item Filter stage uses line buffers and sliding window for memory efficiency
\end{itemize}

\textbf{\faChartLine\hspace{2mm}Throughput Analysis:}
\begin{itemize}[label=\textcolor{primaryBlue}{\faCircle[regular]}, itemsep=1mm, leftmargin=5mm]
    \item \textbf{All Stages:} Process 64 pixels/cycle (II=1 for 512-bit chunks)
    \item \textbf{Filter Latency:} Extended loop (\texttt{+CHUNKS\_PER\_ROW+1} iterations) to fill and drain the sliding window, due to convolution
    \item \textbf{Key Improvement:} Eliminates the 1-pixel/cycle bottleneck from V1 filtering
\end{itemize}

\textbf{\faFilter\hspace{2mm}Filter Stage Implementation:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item \textbf{Line Buffers:} \texttt{uint512\_t lb[2][CHUNKS\_PER\_ROW]}\\ {\small\textcolor{textMuted}{Stores 2 rows of 512-bit chunks for vertical neighbor access}}
    \item \textbf{Sliding Window:} \texttt{uint512\_t win[3][3]}\\ {\small\textcolor{textMuted}{3$\times$3 grid of chunks --- center chunk \texttt{win[1][1]} contains pixels being filtered}}
\end{itemize}

\textbf{\faArrowsAltH\hspace{2mm}West/East Neighbor Access:}
{\small Handles chunk boundaries explicitly:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item West neighbor at $k=0$: Access \texttt{win[1][0].range(511, 504)}
    \item East neighbor at $k=63$: Access \texttt{win[1][2].range(7, 0)}
\end{itemize}

\textbf{\faCogs\hspace{2mm}Key Optimizations:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item \texttt{\#pragma HLS ARRAY\_PARTITION variable=lb complete dim=1}\\ {\small\textcolor{textMuted}{Both line buffer rows accessible in parallel}}
    \item \texttt{\#pragma HLS ARRAY\_PARTITION variable=win complete dim=0}\\ {\small\textcolor{textMuted}{Entire 3$\times$3 sliding window accessible simultaneously}}
    \item \texttt{\#pragma HLS PIPELINE II=1} on all major loops
\end{itemize}

\textbf{\faBalanceScale\hspace{2mm}Trade-offs:}
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item[\textcolor{successGreen}{\faCheckCircle}] 64$\times$ faster filter stage compared to V1's pixel-by-pixel approach
    \item[\textcolor{successGreen}{\faCheckCircle}] Less BRAM usage (no array partitioning needed unlike V1)
    \item[\textcolor{dangerRed}{\faTimesCircle}] Complex sliding window logic with chunk boundary handling
    \item[\textcolor{dangerRed}{\faTimesCircle}] Still sequential execution (stages do not overlap)
\end{itemize}
\end{versionbox}

\begin{versionbox}{Version 3: Dataflow Streaming Architecture (Ultra-Optimized)}
\textbf{\faFile*[regular]\hspace{2mm}File:} \texttt{src\_hw/accelerated\_v3.cpp}

\vspace{4mm}

\textbf{\faCubes\hspace{2mm}Architecture Overview:}
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, itemsep=1.5mm, leftmargin=5mm]
    \item \textbf{True dataflow} with \texttt{\#pragma HLS DATAFLOW}
    \item Three concurrent stages connected via \texttt{hls::stream<uint512\_t>}
    \item Pipeline parallelism: all stages execute simultaneously on different data chunks
\end{itemize}

\textbf{\faLayerGroup\hspace{2mm}Stage Functions:}
\begin{enumerate}[label=\textcolor{warningOrange}{\arabic*.}, itemsep=1.5mm, leftmargin=6mm]
    \item \texttt{compute\_diff\_wide()}: Reads A/B, computes posterized difference, writes to \texttt{stream\_post}
    \item \texttt{apply\_filter\_wide()}: Reads from \texttt{stream\_post}, applies sharpen filter, writes to \texttt{stream\_filt}
    \item \texttt{write\_result\_wide()}: Reads from \texttt{stream\_filt}, writes to output memory C
\end{enumerate}

\textbf{\faStream\hspace{2mm}Stream Configuration:}
\begin{lstlisting}[language=C++]
hls::stream<uint512_t> stream_post("s_post");
hls::stream<uint512_t> stream_filt("s_filt");
#pragma HLS STREAM variable=stream_post depth=16
#pragma HLS STREAM variable=stream_filt depth=16
\end{lstlisting}

\textbf{\faRocket\hspace{2mm}Expected Performance:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item \textbf{Throughput:} 64 pixels per clock cycle
    \item \textbf{Latency:} Theoretical minimum of 1,024 cycles {\small\textcolor{textMuted}{($256 \times 256$ pixels $\div$ 64 pixels/cycle)}}
\end{itemize}

\textbf{\faCogs\hspace{2mm}Key Optimizations:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item \texttt{\#pragma HLS DATAFLOW}\\ {\small\textcolor{textMuted}{Enables concurrent execution: Total latency = $\max(\text{Stage Latencies})$ instead of $\sum$}}
    \item \texttt{\#pragma HLS PIPELINE II=1} inside each function\\ {\small\textcolor{textMuted}{Achieves single-cycle throughput per 512-bit chunk}}
    \item \texttt{\#pragma HLS STREAM variable=... depth=16}\\ {\small\textcolor{textMuted}{Provides buffering slack to prevent producer-consumer stalls}}
\end{itemize}

\textbf{\faBalanceScale\hspace{2mm}Trade-offs:}
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item[\textcolor{successGreen}{\faCheckCircle}] Highest throughput due to overlapped stage execution
    \item[\textcolor{successGreen}{\faCheckCircle}] Memory-efficient streaming (no full-frame buffering)
    \item[\textcolor{dangerRed}{\faTimesCircle}] Most complex implementation
\end{itemize}
\end{versionbox}

\section{HLS Synthesis Results}

\begin{mytitledbox}{Vitis HLS Synthesis Comparison (256×256 Image)}

\begin{table}[H]
    \centering
    \caption{Latency and resource utilization comparison across versions.}
    \label{tab:hls_comparison}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Target Clock Period (ns) & 10.00 & 10.00 & 10.00 \\
        Estimated Clock (ns) & \textbf{7.30} & \textbf{7.30} & \textbf{7.30} \\
        \rowcolor{lightBlueBg!55} Latency (cycles) & \textbf{67632} & \textbf{3104} & \textbf{1048} \\
        \midrule[0.8pt]
        \multicolumn{4}{c}{\textbf{Resource Utilization}} \\
        \midrule[0.8pt]
        DSP48E & \textbf{18} & \textbf{0} & \textbf{0} \\
        \rowcolor{lightBlueBg!55} BRAM\_18K & \textbf{256} & \textbf{30} & \textbf{0} \\
        Flip-Flops (FF) & \textbf{21841} & \textbf{19876} & \textbf{22975} \\
        \rowcolor{lightBlueBg!55} LUTs & \textbf{54593} & \textbf{38816} & \textbf{40869} \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\vspace{2mm}

\subsection*{Loop-Level Latency Breakdown}

The Vitis HLS Performance \& Resource Estimates provide detailed loop-level latency analysis, revealing the bottlenecks in each implementation.

\begin{table}[H]
    \centering
    \caption{V1 loop-level breakdown: Sequential three-stage pipeline.}
    \label{tab:v1_breakdown}
    
    \begin{tabular}{@{}l r r@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Module / Loop}} & \textbf{\textcolor{primaryBlue}{Latency (cycles)}} & \textbf{\textcolor{primaryBlue}{\% of Total}} \\
        \midrule[0.8pt]
        \texttt{IMAGE\_DIFF\_POSTERIZE} (Top) & \textbf{67,632} & 100\% \\
        \midrule
        \quad \texttt{Pipeline\_Posterize\_Main\_Loop} & 1,027 & 1.5\% \\
        \rowcolor{lightBlueBg!55} \quad \texttt{Pipeline\_Filter\_Row\_Filter\_Col} & \textbf{65,551} & \textbf{97.0\%} \\
        \quad \texttt{Pipeline\_Pack\_Main\_Loop} & 1,027 & 1.5\% \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\begin{solutionbox}
{\color{dangerRed}\faExclamationTriangle}\hspace{2mm}\textbf{V1 Bottleneck Analysis:}

\vspace{2mm}

The filter stage (\texttt{Pipeline\_Filter\_Row\_Filter\_Col}) accounts for \highlight{97\%} of total latency. This is because:
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1mm]
    \item The nested loop processes \textbf{one pixel per cycle} (II=1 on inner loop only)
    \item Total filter cycles = HEIGHT $\times$ WIDTH = 256 $\times$ 256 = 65,536 cycles
\end{itemize}
    {\color{warningOrange}\faExclamationCircle}\hspace{2mm}\textbf{Optimization Opportunity:}
    \vspace{1mm}
    The posterize and pack stages already leverage 512-bit parallelism (64 pixels/cycle). Extending this to the filter stage could reduce it from 65,536 to just 1,024 cycles
\end{solutionbox}

\begin{table}[H]
    \centering
    \caption{V2 loop-level breakdown: Sequential with line buffer optimization.}
    \label{tab:v2_breakdown}
    
    \begin{tabular}{@{}l r r@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Module / Loop}} & \textbf{\textcolor{primaryBlue}{Latency (cycles)}} & \textbf{\textcolor{primaryBlue}{\% of Total}} \\
        \midrule[0.8pt]
        \texttt{IMAGE\_DIFF\_POSTERIZE} (Top) & \textbf{3,104} & 100\% \\
        \midrule
        \quad \texttt{Pipeline\_Posterize\_Loop} & 1,027 & 33.2\% \\
        \rowcolor{lightBlueBg!55} \quad \texttt{Pipeline\_Filter\_Loop} & 1,042 & 33.6\% \\
        \quad \texttt{Pipeline\_Write\_Loop} & 1,027 & 33.2\% \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\begin{solutionbox}
{\color{successGreen}\faLightbulb}\hspace{2mm}\textbf{V2 Optimization Strategy:}

\vspace{2mm}

By switching to line buffers and a sliding window approach, V2 achieves:
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1mm]
    \item \highlight{63× faster} filter stage (1,032 vs 65,551 cycles)
    \item Balanced stage latencies: Posterize (1,027), Filter (1,042), Write (1,027)
\end{itemize}

{\color{warningOrange}\faExclamationCircle}\hspace{2mm}\textbf{Optimization Opportunity:}
\vspace{1mm}
With nearly identical stage latencies ($\sim$1,030 cycles each), the three stages could run \textit{concurrently} using HLS streams and \texttt{DATAFLOW}. This would reduce total latency from $\sum = 3,104$ cycles to $\max = 1,042$ cycles, a \highlight{3$\times$ improvement}. The key change is replacing BRAM intermediate buffers with \texttt{stream} FIFOs and refactoring each stage into a separate function.

\end{solutionbox}


\begin{table}[H]
    \centering
    \caption{V3 module-level breakdown: Dataflow streaming architecture.}
    \label{tab:v3_breakdown}
    
    \begin{tabular}{@{}l r@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Module / Function}} & \textbf{\textcolor{primaryBlue}{Latency (cycles)}} \\
        \midrule[0.8pt]
        \texttt{IMAGE\_DIFF\_POSTERIZE} (Top) & \textbf{1,049} \\
        \midrule
        \quad \texttt{compute\_diff\_wide} & 1,035 \\
        \rowcolor{lightBlueBg!55} \quad \texttt{apply\_filter\_wide} & \textbf{1,042} \\
        \quad \texttt{write\_result\_wide} & 1,035 \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\begin{solutionbox}
{\color{secondaryTeal}\faBolt}\hspace{2mm}\textbf{V3 Dataflow Parallelism:}

\vspace{2mm}

With \texttt{\#pragma HLS DATAFLOW}, all three functions execute \textbf{concurrently}. Instead of waiting for one stage to complete before starting the next, stages process different chunks simultaneously.

\vspace{2mm}
The total latency equals the \textbf{slowest stage} (1,042 cycles for \texttt{apply\_filter\_wide}) plus pipeline fill/drain overhead ($\sim$7 cycles), achieving \highlight{1,049 cycles}, only \textbf{2.4\% above} the theoretical minimum of 1,024 cycles for a 256×256 image.

\vspace{2mm}
{\color{successGreen}\faCheckCircle}\hspace{2mm}\textbf{Key Insight:} Balanced stage latencies are critical for dataflow efficiency. If one stage were significantly slower, it would bottleneck the entire pipeline.
\end{solutionbox}

\newpage

\section{Vitis IDE Execution Results}

The following results are obtained from running Emulation-HW using Vitis IDE.

\subsection{Kernel Execution Statistics}

\begin{mytitledbox}{Kernels \& Compute Units $\rightarrow$ Kernel Execution}

\vspace{-2mm}  % Counteract the top padding

\begin{table}[H]
    \centering
    \caption{Kernel execution metrics from Vitis IDE.}
    \label{tab:kernel_exec}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Kernel Name & IMAGE\_DIFF & IMAGE\_DIFF & IMAGE\_DIFF \\
        \rowcolor{lightBlueBg!55} Clock Frequency (MHz) & 300 & 300 & 300 \\
        \textbf{Compute Unit Time ($\mu$s)} & \textbf{230} & \textbf{15} & \textbf{11} \\
        \rowcolor{lightBlueBg!55} Kernel Execution Time ($\mu$s) & 233 & 22 & 16 \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

{\small\textcolor{textMuted}{\faInfoCircle\hspace{2mm}Source for clock frequency: \texttt{hw\_link $\rightarrow$ Emulation-HW $\rightarrow$ binary\_container $\rightarrow$ Link Summary}. Target: 300 MHz, Estimated: \textbf{411 MHz}.}}

\end{mytitledbox}

\begin{solutionbox}
{\color{accentBlue}\faInfoCircle}\hspace{2mm}\textbf{Compute Unit Time vs. Kernel Execution Time:}

\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1.5mm]
    \item \textbf{Compute Unit (CU) Time:} Measures the time the hardware compute unit is actively executing, from when the CU starts processing to when it signals completion. This reflects the \textit{pure hardware execution time} including any memory stalls within the CU.
    
    \item \textbf{Kernel Execution Time:} Measures the total time from when the host issues the kernel launch (e.g., \texttt{clEnqueueNDRangeKernel}) to when the kernel completes. This includes CU Time \textit{plus} software overhead (eg kernel setup)
\end{itemize}

{\small\textcolor{textMuted}{\faLightbulb\hspace{2mm}The difference represents the runtime/launch overhead, which is $\approx constant$ regardless of kernel complexity. For faster kernels, it becomes a larger fraction of total time.}}
\end{solutionbox}

\subsection{Kernel Data Transfers}

\begin{mytitledbox}{Kernel Data Transfers $\rightarrow$ Top Kernel Data Transfer}

\vspace{-2mm}  % Counteract the top padding

\begin{table}[H]
    \centering
    \caption{Top kernel data transfer statistics.}
    \label{tab:kernel_transfers}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Total Transfers & \textbf{64} & \textbf{64} & \textbf{64} \\
        \rowcolor{lightBlueBg!55} Transfer Rate (MB/s) & \textbf{9595.3} & \textbf{9595.3} & \textbf{8868.2} \\
        Avg Transfer Size (Bytes) & \textbf{1024} & \textbf{1024} & \textbf{1024} \\
        \rowcolor{lightBlueBg!55} Link Utilization (\%) & \textbf{25} & \textbf{25} & \textbf{25} \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}


\subsubsection{Understanding Kernel Transfer Metrics}

\begin{solutionbox}
{\color{accentBlue}\faDatabase}\hspace{2mm}\textbf{Mechanism: AXI Burst Inference}

\vspace{2mm}

The discrepancy between the code's 64-byte read and the profiler's 1024-byte transfer is due to \textbf{Burst Inference}. The HLS compiler analyzes the access pattern in the loop:
\begin{itemize}[label=\textcolor{accentBlue}{\faCode}, leftmargin=5mm, itemsep=0mm]
    \item \texttt{for (int i = 0; i < TOTAL\_CHUNKS; i++) \{ ... A[i] ... \}}
\end{itemize}
Because memory addresses are accessed sequentially ($i, i+1, i+2\dots$) inside a pipelined loop (II=1), the memory controller groups multiple logical requests into a single physical transaction to amortize control overhead.

\vspace{2mm}
{\color{purpleAccent}\faCalculator}\hspace{2mm}\textbf{Deriving the 1024-Byte Transfer Size}

\vspace{2mm}

The AXI interface uses a \textit{Burst Length} of 16 beats to saturate bandwidth:
\begin{itemize}[label=\textcolor{purpleAccent}\faAngleRight, leftmargin=5mm, itemsep=1mm]
    \item \textbf{1 Beat (Logical Read):} Defined by \texttt{uint512\_t} = 512 bits = \textbf{64 Bytes}.
    \item \textbf{1 Burst (Physical Tx):} The controller coalesces 16 beats per transaction.
    \item \textbf{Calculation:} $16 \text{ beats} \times 64 \text{ bytes/beat} = \mathbf{1024 \text{ Bytes}}$.
\end{itemize}

\vspace{1mm}
\noindent\textbf{Verification against Profiler Data:}

\vspace{2mm}

\begin{tabular}{@{}ll@{}}
\textbf{Total Image Size:} & $256 \times 256 \text{ pixels} = 65,536 \text{ Bytes (64 KB)}$ \\
\textbf{Total Transfers:} & $65,536 \text{ Bytes} \div 1024 \text{ Bytes/Burst} = \mathbf{64 \text{ Transfers}}$ \\
\end{tabular}
\end{solutionbox}

\begin{solutionbox}
{\color{warningOrange}\faQuestionCircle}\hspace{2mm}\textbf{Why V1 \& V2 have same Transfer Rates and higher than V3?}

\vspace{2mm}
\textbf{V1 and V2} share the same \textbf{sequential execution model}:
\begin{enumerate}[label=\textcolor{accentBlue}{\arabic*.}, itemsep=1mm, leftmargin=6mm]
    \item Read all input data (A, B) $\rightarrow$ store in local BRAM
    \item Process (posterize, filter)
    \item Write all output (C) to DDR
\end{enumerate}

This creates \textbf{non-overlapping, sequential memory bursts} that fully utilize the AXI bus during each phase, achieving maximum burst efficiency (\textbf{9595.3 MB/s}).

\vspace{3mm}
\textbf{V3} uses \texttt{\#pragma HLS DATAFLOW}, making all stages run \textbf{concurrently}:
\begin{itemize}[label=\textcolor{dangerRed}{$\bullet$}, leftmargin=5mm, itemsep=1mm]
    \item \texttt{compute\_diff\_wide} is \textbf{reading} from A/B
    \item \texttt{write\_result\_wide} is \textbf{writing} to C
    \item Both compete for the \textbf{same memory controller} simultaneously
\end{itemize}

This \textbf{memory contention} reduces the effective transfer rate to \textbf{8868.2 MB/s}. However, the trade-off is worthwhile, since V3's overlapped execution still achieves the \highlight{fastest execution time (11 $\mu$s)}.
\end{solutionbox}



\begin{solutionbox}
{\color{warningOrange}\faExclamationCircle}\hspace{2mm}\textbf{Transfer Efficiency = 25\%:}

Vitis calculates transfer efficiency using this formula:
$$\text{Efficiency} = \frac{\text{Average Bytes}}{\min(\text{Memory Byte Width} \times 256, 4096)}$$

For V3:
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item Memory Byte Width: $512 \div 8 = 64$ bytes
    \item Memory Width $\times$ 256: $64 \times 256 = 16384$ bytes
    \item $\min(16384, 4096) = \mathbf{4096}$ bytes (DDR page size limit)
    \item Efficiency: $1024 \div 4096 = \mathbf{25\%}$
\end{itemize}

\end{solutionbox}

\subsection{Host Data Transfers}

\begin{mytitledbox}{Host Data Transfer $\rightarrow$ Host Transfer}

\begin{table}[H]
    \centering
    \caption{Host-to-device and device-to-host transfer statistics (same for all versions).}
    \label{tab:host_transfers}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{Host to Device}} & \textbf{\textcolor{primaryBlue}{Device to Host}} & \textbf{\textcolor{primaryBlue}{Unit}} \\
        \midrule[0.8pt]
        Transfer Count & \textbf{1} & \textbf{1} & -- \\
        \rowcolor{lightBlueBg!55} Transfer Rate & \textbf{3.151} & \textbf{3.135} & MB/s \\
        Avg Transfer Size & \textbf{131,072} & \textbf{65,536} & Bytes \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\subsubsection*{Understanding Host vs Kernel Transfer Rate Difference}

\begin{solutionbox}
{\color{dangerRed}\faExclamationTriangle}\hspace{2mm}\textbf{Dramatic Rate Difference:}

\vspace{2mm}

\begin{tabular}{@{}lrl@{}}
\textbf{Host $\leftrightarrow$ Device:} & $\sim$3 MB/s & (PCIe path) \\
\textbf{Kernel $\leftrightarrow$ DDR:} & $\sim$9000 MB/s & (On-chip AXI path) \\
\textbf{Ratio:} & $\sim$3000$\times$ & slower for host transfers \\
\end{tabular}

\vspace{3mm}
{\color{accentBlue}\faQuestionCircle}\hspace{2mm}\textbf{Why Such a Large Difference?}

\begin{enumerate}[label=\textcolor{accentBlue}{\arabic*.}, itemsep=2mm, leftmargin=6mm]
    \item \textbf{Hardware Emulation vs Real Hardware:} The $\sim$3 MB/s rate is characteristic of \texttt{hw\_emu} mode, where PCIe transfers are \textit{simulated in software}. On real FPGA hardware, PCIe Gen3 x16 achieves 8--12 GB/s.
    
    \item \textbf{Different Memory Paths:}
    \begin{itemize}[label=\textcolor{purpleAccent}{$\bullet$}, leftmargin=4mm]
        \item \textbf{Kernel $\leftrightarrow$ DDR:} Uses on-chip 512-bit wide AXI bus directly connected to DDR memory controller
        \item \textbf{Host $\leftrightarrow$ Device:} Traverses PCIe bus with DMA engines
    \end{itemize}
    
\end{enumerate}
\end{solutionbox}

\begin{solutionbox}
{\faInfoCircle}\hspace{2mm}\textbf{Host Transfer Size Breakdown:}

\vspace{2mm}

\begin{tabular}{@{}lr@{}}
\textbf{Host $\rightarrow$ Device (WRITE):} & \textbf{131072 Bytes} \\
\quad Buffer A (input image 1): & 65536 Bytes \\
\quad Buffer B (input image 2): & 65536 Bytes \\
\\
\textbf{Device $\rightarrow$ Host (READ):} & \textbf{65536 Bytes} \\
\quad Buffer C (output image): & 65536 Bytes \\
\end{tabular}

\vspace{2mm}
{\small\textcolor{textMuted}{\faInfoCircle\hspace{2mm}Buffer size = TOTAL\_CHUNKS $\times$ PIXELS\_CHUNK = $1024 \times 64 = 65536$ Bytes}}
\end{solutionbox}

\section{Performance Comparison Summary}

\begin{mytitledbox}{Overall Performance Comparison}

\begin{table}[H]
    \centering
    \caption{Summary comparison of all three implementations.}
    \label{tab:summary}
    
    \begin{tabular}{@{}p{0.35\textwidth} c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Characteristic}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Architecture & Sequential & Sequential & Dataflow \\
        \rowcolor{lightBlueBg!55} Buffer Type & 2D Arrays & 512-bit Chunks & Streams \\
        Filter Implementation & Direct 2D & Line Buffer & Line Buffer \\
        \rowcolor{lightBlueBg!55} Stage Parallelism & None & None & Full Overlap \\
        \midrule[0.8pt]
        HLS Latency (cycles) & \textbf{67632} & \textbf{3104} & \textbf{1048} \\
        \rowcolor{lightBlueBg!55} FPGA Exec Time ($\mu$s) & \textbf{230} & \textbf{15} & \textbf{11} \\
        BRAM Usage & High & Medium & Low \\
        \rowcolor{lightBlueBg!55} Implementation Complexity & Low & Medium & High \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\subsection{Theoretical Speed-up Calculation}

\begin{solutionbox}
\hspace{2mm}\textbf{V3 vs V1 Speed-up:}
$$ \text{Speedup} = \frac{\text{Latency}_{V1}}{\text{Latency}_{V3}} = \frac{67632}{1048} \approx \mathbf{64.5 \times} $$

\hspace{2mm}\textbf{V3 vs V2 Speed-up:}
$$ \text{Speedup} = \frac{\text{Latency}_{V2}}{\text{Latency}_{V3}} = \frac{3104}{1048} \approx \mathbf{2.96 \times} $$
\end{solutionbox}


\subsection{Theoretical vs. Actual Performance Analysis}

\begin{solutionbox}
{\color{accentBlue}\faInfoCircle}\hspace{2mm}\textbf{The Discrepancy: Port Parallelism vs. Memory Bandwidth}

Although the code defines separate AXI bundles (\texttt{gmemA}, \texttt{gmemB}, \texttt{gmemC}) to create independent ports on the FPGA, the default system configuration maps all these ports to a \textbf{single shared DDR memory bank}.

This creates a classic "Many-to-One" bottleneck:

\begin{itemize}[label=\textcolor{dangerRed}{\faExclamationTriangle}, leftmargin=5mm, itemsep=2mm]
    \item \textbf{FPGA Demand:} The V3 kernel attempts to Read A, Read B, and Write C simultaneously. At 300 MHz with 512-bit width, the requested aggregate bandwidth is:
    $$ \text{BW per stream} = \frac{512 \text{ bits}}{8} \times 300 \text{ MHz} = 64 \text{ B} \times 300 \text{ M/s} = 19.2 \text{ GB/s} $$
    $$ \text{Total Demand} = 3 \text{ streams} \times 19.2 \text{ GB/s} \approx \mathbf{57.6 \text{ GB/s}} $$
    
    \item \textbf{Memory Supply:} A single DDR4 channel (typical in emulation and default hardware mapping) has a peak theoretical bandwidth of only $\approx \mathbf{19.2 \text{ GB/s}}$.
\end{itemize}

\vspace{2mm}
\textbf{The Resulting Slowdown:}
Since the memory controller cannot serve 57.6 GB/s, it throttles the kernel. The effective execution time becomes determined by the memory limit, not the compute logic:

$$ \text{Actual Time} \approx \text{Ideal Compute Time} \times \frac{\text{Demand}}{\text{Supply}} $$
$$ 11 \mu s \approx 3.5 \mu s \times 3 $$

{\small\textcolor{textMuted}{\faInfoCircle\hspace{2mm}Note: This 3$\times$ ratio is a first-order approximation. Actual performance may vary slightly due to memory arbitration overhead, burst scheduling inefficiencies, and controller latency.}}

\vspace{2mm}
This confirms that while \texttt{accelerated\_v3} is logically capable of 3.5 $\mu$s execution, it is strictly \textbf{memory bound} in this system configuration. To realize the full potential of V3, one would need to map \texttt{gmemA}, \texttt{gmemB}, and \texttt{gmemC} to separate physical DDR banks (e.g., DDR[0], DDR[1], DDR[2]) using a connectivity configuration file.
\end{solutionbox}

\section{Conclusion}

\begin{tcolorbox}[mybox]
\faFlagCheckered\hspace{2mm}This laboratory exercise explored three architectural approaches for implementing an image processing accelerator with difference, posterization, and sharpening operations:

\begin{itemize}[leftmargin=5mm, itemsep=3mm]
    \item \textbf{V1 (Sequential + 2D Buffers):} Simplest implementation with straightforward 2D array access for the filter stage. Trades off memory for simplicity.
    
    \item \textbf{V2 (Sequential + Line Buffers):} More memory-efficient filter implementation using sliding window on 512-bit chunks, but still sequential execution.
    
    \item \textbf{V3 (Dataflow + Streams):} Achieves maximum performance through pipeline parallelism with HLS streams. All stages execute concurrently, approaching theoretical minimum latency.
\end{itemize}

\vspace{3mm}
\textcolor{textMuted}{\faLightbulb}\hspace{2mm}\textit{The results demonstrate the trade-offs between implementation complexity, resource utilization, and performance. The dataflow architecture (V3) provides the best performance but requires careful design of stream depths and stage balancing.}
\end{tcolorbox}

\vspace{5mm}
\noindent\textcolor{textMuted}{\faBook\hspace{2mm}\textbf{Reference:}} For more details on interpreting the Vitis profile summary, see the official AMD documentation: \href{https://docs.amd.com/r/2022.1-English/ug1393-vitis-application-acceleration/Interpreting-the-Profile-Summary}{Interpreting the Profile Summary}.

\end{document}
