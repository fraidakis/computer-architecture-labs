\documentclass[12pt,a4paper]{article}

% Essential packages
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{listings}
\usepackage[table]{xcolor}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{enumitem}
\usepackage{float}
\usepackage{enumitem}

% Additional packages for beautification
\usepackage[skins,breakable,raster]{tcolorbox}
\usepackage{fontspec}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{tikz}
\usepackage{pifont}  % For checkmarks and symbols
\usepackage{fontawesome5}  % Modern icons
\usepackage{colortbl}

\usetikzlibrary{shadows.blur,positioning,calc,decorations.pathmorphing}

\usepackage{array}
\setlength{\tabcolsep}{8pt}

% ============================================
% MODERN COLOR PALETTE
% ============================================
\definecolor{primaryBlue}{RGB}{26,54,93}        % Deep navy
\definecolor{accentBlue}{RGB}{59,130,246}       % Bright blue
\definecolor{secondaryTeal}{RGB}{20,184,166}    % Teal accent
\definecolor{warningOrange}{RGB}{249,115,22}    % Orange
\definecolor{successGreen}{RGB}{34,197,94}      % Green
\definecolor{dangerRed}{RGB}{239,68,68}         % Red
\definecolor{purpleAccent}{RGB}{139,92,246}     % Purple
\definecolor{lightBlueBg}{RGB}{239,246,255}     % Light blue bg
\definecolor{lightTealBg}{RGB}{240,253,250}     % Light teal bg
\definecolor{lightPurpleBg}{RGB}{250,245,255}   % Light purple bg
\definecolor{codeGray}{RGB}{249,250,251}        % Code background
\definecolor{borderGray}{RGB}{226,232,240}      % Border color
\definecolor{textDark}{RGB}{30,41,59}           % Dark text
\definecolor{textMuted}{RGB}{100,116,139}       % Muted text

% ============================================
% HYPERLINK STYLING
% ============================================
\hypersetup{
    colorlinks=true,
    linkcolor=accentBlue,
    filecolor=accentBlue,
    urlcolor=accentBlue,
    citecolor=accentBlue
}

% ============================================
% CUSTOM TCOLORBOX STYLES - MODERN DESIGN
% ============================================

% Main content box with shadow
\tcbset{
    mybox/.style={
        enhanced,
        colback=lightBlueBg,
        colframe=accentBlue,
        arc=4mm,
        boxrule=1pt,
        left=4mm,
        right=4mm,
        top=3mm,
        bottom=3mm,
        drop shadow={shadow xshift=0.5mm, shadow yshift=-0.5mm, opacity=0.15}
    }
}

% Titled box with gradient-like header
\newtcolorbox{mytitledbox}[1]{
    enhanced,
    colback=white,
    colframe=primaryBlue,
    arc=4mm,
    boxrule=1.2pt,
    title={\faChartBar\hspace{2mm}\textbf{#1}},
    coltitle=white,
    fonttitle=\bfseries\sffamily,
    colbacktitle=primaryBlue,
    attach boxed title to top left={yshift=-2mm, xshift=4mm},
    boxed title style={arc=2mm, boxrule=0pt},
    top=6mm,
    drop shadow={shadow xshift=0.5mm, shadow yshift=-0.5mm, opacity=0.12}
}

% Solution/Analysis box with left accent bar
\newtcolorbox{solutionbox}{
    enhanced,
    colback=lightBlueBg,
    colframe=borderGray,
    arc=2mm,
    boxrule=0.5pt,
    borderline west={3pt}{0pt}{accentBlue},
    left=6mm,
    right=4mm,
    top=3mm,
    bottom=3mm,
    before=\vspace{3mm},
    after=\vspace{3mm},
    breakable
}

% Version boxes with modern styling
\newtcolorbox{versionbox}[1]{
    enhanced,
colback=lightPurpleBg,
colframe=purpleAccent,
colbacktitle=purpleAccent,
    arc=4mm,
    boxrule=1pt,
    title={\faMicrochip\hspace{2mm}\textbf{#1}},
    coltitle=white,
    fonttitle=\bfseries\sffamily,
    attach boxed title to top left={yshift=-2mm, xshift=4mm},
    boxed title style={arc=2mm, boxrule=0pt},
    top=6mm,
    left=4mm,
    right=4mm,
    bottom=3mm,
    drop shadow={shadow xshift=0.5mm, shadow yshift=-0.5mm, opacity=0.12}
}

% Info box (blue)
\newtcolorbox{infobox}{
    enhanced,
    colback=lightBlueBg,
    colframe=accentBlue,
    arc=3mm,
    boxrule=0.8pt,
    borderline west={3pt}{0pt}{accentBlue},
    left=6mm,
    before skip=4mm,
    after skip=4mm
}

% Tip box (green)
\newtcolorbox{tipbox}{
    enhanced,
    colback=lightTealBg,
    colframe=secondaryTeal,
    arc=3mm,
    boxrule=0.8pt,
    borderline west={3pt}{0pt}{successGreen},
    left=6mm,
    before skip=4mm,
    after skip=4mm
}

% Warning box (orange)
\newtcolorbox{warningbox}{
    enhanced,
    colback=lightOrangeBg,
    colframe=warningOrange,
    arc=3mm,
    boxrule=0.8pt,
    borderline west={3pt}{0pt}{warningOrange},
    left=6mm,
    before skip=4mm,
    after skip=4mm
}

% ============================================
% HEADER AND FOOTER SETUP
% ============================================
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{1.2pt}
\renewcommand{\headrule}{\hbox to\headwidth{\color{primaryBlue}\leaders\hrule height \headrulewidth\hfill}}
\renewcommand{\footrulewidth}{0.4pt}
\renewcommand{\footrule}{\hbox to\headwidth{\color{borderGray}\leaders\hrule height \footrulewidth\hfill}}
\fancyhead[L]{\sffamily\textcolor{primaryBlue}{\faMicrochip\hspace{2mm}Computer Architecture Laboratory}}
\fancyhead[R]{\sffamily\textcolor{primaryBlue}{Lab 2 Report\hspace{2mm}\faFlask}}
\fancyfoot[C]{\sffamily\textcolor{textMuted}{\thepage}}
\setlength{\headheight}{16pt}
\addtolength{\topmargin}{-2.5pt}

% ============================================
% SECTION STYLING WITH DECORATIONS
% ============================================
\usepackage{titlesec}

\titleformat{\section}
  {\normalfont\Large\bfseries\sffamily\color{primaryBlue}}
  {\colorbox{primaryBlue}{\textcolor{white}{\thesection}}}{0.8em}{}[{\color{primaryBlue}\titlerule[1.5pt]}]
\titlespacing*{\section}{0pt}{12pt plus 4pt minus 2pt}{8pt plus 2pt minus 2pt}

\titleformat{\subsection}
  {\normalfont\large\bfseries\sffamily\color{primaryBlue}}
  {\textcolor{accentBlue}{\thesubsection}}{0.8em}{}[]
\titlespacing*{\subsection}{0pt}{10pt plus 4pt minus 2pt}{6pt plus 2pt minus 2pt}

\titleformat{\subsubsection}
  {\normalfont\normalsize\bfseries\sffamily\color{primaryBlue}}
  {\textcolor{secondaryTeal}{\thesubsubsection}}{0.8em}{}

% ============================================
% CODE LISTING STYLE - MODERN
% ============================================
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{codeGray},
    commentstyle=\color{successGreen}\itshape,
    keywordstyle=\color{accentBlue}\bfseries,
    numberstyle=\tiny\color{textMuted}\sffamily,
    stringstyle=\color{purpleAccent},
    basicstyle=\ttfamily\small,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=8pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single,
    framesep=6pt,
    framerule=0.8pt,
    rulecolor=\color{borderGray},
    framexleftmargin=8pt,
    framexrightmargin=6pt,
    framextopmargin=5pt,
    framexbottommargin=5pt,
    xleftmargin=12pt,
    xrightmargin=6pt,
}
\lstset{style=mystyle}

% ============================================
% CUSTOM COMMANDS FOR ICONS AND STYLING
% ============================================
\newcommand{\mycheck}{\textcolor{successGreen}{\ding{51}}}
\newcommand{\mycross}{\textcolor{dangerRed}{\ding{55}}}
\newcommand{\promark}{\textcolor{successGreen}{$+$}}
\newcommand{\conmark}{\textcolor{dangerRed}{$-$}}
\newcommand{\bulletpoint}{\textcolor{accentBlue}{\faAngleRight}}
\newcommand{\highlight}[1]{\colorbox{lightBlueBg}{\textcolor{primaryBlue}{\textbf{#1}}}}

% Custom table column types
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}}

% ==========================================
% TITLE PAGE
% ==========================================

\title{
    \vspace*{1.5cm}
    {\fontsize{42}{50}\selectfont\bfseries\sffamily\textcolor{primaryBlue}{Computer Architecture}}\\[0.3cm]
    {\fontsize{28}{36}\selectfont\sffamily\textcolor{accentBlue}{Laboratory Report}}\\[1.2cm]
    {\color{primaryBlue}\rule{0.8\textwidth}{2pt}}\\[0.8cm]
    {\LARGE\sffamily\textcolor{textDark}{Lab 2: Image Processing Accelerator}}\\[0.3cm]
    {\Large\sffamily\textcolor{textMuted}{with Sharpening Filter}}\\[1.5cm]
    \fbox{\parbox{0.4\textwidth}{\centering
        \vspace{3mm}
        {\large\sffamily\textcolor{textMuted}{Author}}\\[3mm]
        {\Large\bfseries\sffamily\textcolor{primaryBlue}{Fraidakis Ioannis}}
        \vspace{3mm}
    }}\\[2cm]
    {\color{borderGray}\rule{0.3\textwidth}{1pt}}
}
\author{}
\date{{\Large\sffamily\textcolor{textMuted}{December 2025}}}

\begin{document}
\maketitle

\newpage

\section{Introduction}

\begin{tcolorbox}[mybox]
\faLaptopCode\hspace{2mm}This laboratory exercise extends the previous lab by adding a 3×3 sharpening filter to the image processing pipeline. The accelerator now performs three operations in sequence:
\begin{enumerate}[label=\textcolor{accentBlue}{\arabic*.}, itemsep=2mm, leftmargin=6mm]
    \item \textbf{Absolute Difference}: $D[i][j] = |A[i][j] - B[i][j]|$
    \item \textbf{Posterization}: Map $D$ to discrete levels (0, 128, or 255)
    \item \textbf{Sharpen Filter}: Apply a Laplacian-based 3×3 convolution kernel
\end{enumerate}

\vspace{2mm}
\textcolor{textMuted}{\faInfoCircle}\hspace{2mm}\textit{Additionally, three different architectural implementations (V1, V2, V3) were developed to explore optimization strategies for throughput and resource utilization, analyzing trade-offs between memory access patterns, dataflow parallelism, and hardware complexity. These versions were not part of the lab requirements but were implemented as a personal exploration of HLS design techniques.}
\end{tcolorbox}

\section{Algorithm Description}

\subsection{Processing Pipeline}

The image processing pipeline consists of three stages:

\begin{enumerate}
    \item \textbf{Difference Calculation:} For each pixel $(i, j)$:
    $$D[i][j] = |A[i][j] - B[i][j]|$$
    
    \item \textbf{Posterization Thresholding:} 
    $$
    P[i][j] = 
    \begin{cases} 
    0 & \text{if } D < 32 \quad (\text{Black}) \\
    128 & \text{if } 32 \le D < 96 \quad (\text{Gray}) \\
    255 & \text{if } D \ge 96 \quad (\text{White})
    \end{cases}
    $$
    
    \item \textbf{Sharpen Filter:} Apply Laplacian-based 3×3 kernel:
    $$
    K = \begin{bmatrix}
    0 & -1 & 0 \\
    -1 & 5 & -1 \\
    0 & -1 & 0
    \end{bmatrix}
    $$
    The convolution output is computed as:
    $$C[i][j] = 5 \cdot P[i][j] - P[i-1][j] - P[i+1][j] - P[i][j-1] - P[i][j+1]$$
    The result is then clamped to the valid pixel range:
    $$C[i][j] = \min(255, \max(0, C[i][j]))$$
\end{enumerate}

\subsection{Memory Interface}

All implementations use 512-bit wide AXI master interfaces (64 pixels per memory transaction). This aligns with the DDR memory bus width and maximizes memory bandwidth utilization.

\section{Implementation Versions}

This section describes the three accelerator implementations and their architectural differences.

\begin{versionbox}{Version 1: Sequential Three-Stage Pipeline}
\textbf{\faFile*[regular]\hspace{2mm}File:} \texttt{accelerated\_v1.cpp}

\textbf{\faCubes\hspace{2mm}Architecture Overview:}
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, itemsep=1.5mm, leftmargin=5mm]
    \item Three sequential stages that execute one after another
    \item Uses 2D local BRAM buffers (\texttt{C\_tmp[HEIGHT][PADDED\_WIDTH]}, \texttt{C\_filt})
    \item Full-frame buffering (entire image stored in on-chip memory)
\end{itemize}

\textbf{\faLayerGroup\hspace{2mm}Stage Execution:}
\begin{enumerate}[label=\textcolor{warningOrange}{\arabic*.}, itemsep=1.5mm, leftmargin=6mm]
    \item \textbf{Stage 1 (Posterize):} Read 512-bit chunks from A/B, compute difference, posterize, store to \texttt{C\_tmp}
    \item \textbf{Stage 2 (Filter):} Row-by-row filtering with direct 2D array access
    \item \textbf{Stage 3 (Pack):} Read from \texttt{C\_filt}, pack into 512-bit words, write to DDR
\end{enumerate}

\textbf{\faCogs\hspace{2mm}Key Optimizations:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item \texttt{\#pragma HLS ARRAY\_PARTITION variable=C\_tmp cyclic factor=3 dim=1}\\ {\small\textcolor{textMuted}{Enables parallel access to north/center/south rows}}
    \item \texttt{\#pragma HLS ARRAY\_PARTITION variable=C\_tmp cyclic factor=64 dim=2}\\ {\small\textcolor{textMuted}{Enables 64-pixel parallel access}}
    \item \texttt{\#pragma HLS PIPELINE II=1} on all major loops
    \item \texttt{\#pragma HLS UNROLL} for inner 64-pixel processing
\end{itemize}

\textbf{\faBalanceScale\hspace{2mm}Trade-offs:}
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item[\textcolor{successGreen}{\faCheckCircle}] Simple to implement and debug
    \item[\textcolor{successGreen}{\faCheckCircle}] 2D indexing simplifies filter neighbor access
    \item[\textcolor{dangerRed}{\faTimesCircle}] Requires substantial BRAM for full-frame buffering
    \item[\textcolor{dangerRed}{\faTimesCircle}] Stages execute sequentially (no overlap)
\end{itemize}
\end{versionbox}

\newpage

\begin{versionbox}{Version 2: Sequential with Line Buffers}
\textbf{\faFile*[regular]\hspace{2mm}File:} \texttt{accelerated\_v2.cpp}

\textbf{\faCubes\hspace{2mm}Architecture Overview:}
\begin{itemize}
    \item Three sequential stages (same as V1) but with optimized filter stage
    \item Uses 512-bit chunk-based intermediate buffers (\texttt{uint512\_t C\_tmp[TOTAL\_CHUNKS]})
    \item Filter stage uses line buffers and sliding window for memory efficiency
\end{itemize}

\textbf{\faFilter\hspace{2mm}Filter Stage Implementation:}
\begin{itemize}
    \item \textbf{Line Buffers:} \texttt{uint512\_t lb[2][CHUNKS\_PER\_ROW]}\\ {\small\textcolor{textMuted}{Stores 2 rows of 512-bit chunks}}
    \item \textbf{Sliding Window:} \texttt{uint512\_t win[3][3]}\\ {\small\textcolor{textMuted}{3×3 grid of chunks for convolution}}
    \item Extended loop with pipeline drain: \texttt{TOTAL\_CHUNKS + CHUNKS\_PER\_ROW + 1} iterations
\end{itemize}

\textbf{\faArrowsAltH\hspace{2mm}West/East Neighbor Access:}
{\small Handles chunk boundaries explicitly:}
\begin{itemize}
    \item West neighbor at $k=0$: Access \texttt{win[1][0].range(511, 504)}
    \item East neighbor at $k=63$: Access \texttt{win[1][2].range(7, 0)}
\end{itemize}

\textbf{\faBalanceScale\hspace{2mm}Trade-offs:}
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item[\textcolor{successGreen}{\faCheckCircle}] More memory-efficient filter implementation using line buffers
    \item[\textcolor{successGreen}{\faCheckCircle}] Maintains 512-bit data format throughout (no unpack/repack overhead)
    \item[\textcolor{dangerRed}{\faTimesCircle}] Complex sliding window logic with chunk boundary handling
    \item[\textcolor{dangerRed}{\faTimesCircle}] Still sequential execution (no stage overlap)
\end{itemize}
\end{versionbox}

\newpage

\begin{versionbox}{Version 3: Dataflow Streaming Architecture (Ultra-Optimized)}
\textbf{\faFile*[regular]\hspace{2mm}File:} \texttt{accelerated\_v3.cpp}

\textbf{\faCubes\hspace{2mm}Architecture Overview:}
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, itemsep=1.5mm, leftmargin=5mm]
    \item \textbf{True dataflow} with \texttt{\#pragma HLS DATAFLOW}
    \item Three concurrent stages connected via \texttt{hls::stream<uint512\_t>}
    \item Pipeline parallelism: all stages execute simultaneously on different data chunks
\end{itemize}

\textbf{\faLayerGroup\hspace{2mm}Stage Functions:}
\begin{enumerate}[label=\textcolor{warningOrange}{\arabic*.}, itemsep=1.5mm, leftmargin=6mm]
    \item \texttt{compute\_diff\_wide()}: Reads A/B, computes posterized difference, writes to \texttt{stream\_post}
    \item \texttt{apply\_filter\_wide()}: Reads from \texttt{stream\_post}, applies sharpen filter, writes to \texttt{stream\_filt}
    \item \texttt{write\_result\_wide()}: Reads from \texttt{stream\_filt}, writes to output memory C
\end{enumerate}

\textbf{\faStream\hspace{2mm}Stream Configuration:}
\begin{lstlisting}[language=C++]
static hls::stream<uint512_t> stream_post("s_post");
static hls::stream<uint512_t> stream_filt("s_filt");
#pragma HLS STREAM variable=stream_post depth=16
#pragma HLS STREAM variable=stream_filt depth=16
\end{lstlisting}

\textbf{\faTachometerAlt\hspace{2mm}Expected Performance:}
\begin{itemize}[itemsep=1.5mm, leftmargin=5mm]
    \item \textbf{Throughput:} 64 pixels per clock cycle
    \item \textbf{Latency:} $\sim$1,050 cycles {\small\textcolor{textMuted}{(theoretical minimum for 256×256 is 1024 cycles)}}
\end{itemize}

\textbf{\faBalanceScale\hspace{2mm}Trade-offs:}
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item[\textcolor{successGreen}{\faCheckCircle}] Highest throughput due to overlapped stage execution
    \item[\textcolor{successGreen}{\faCheckCircle}] Minimal latency (close to theoretical minimum)
    \item[\textcolor{successGreen}{\faCheckCircle}] Memory-efficient streaming (no full-frame buffering)
    \item[\textcolor{dangerRed}{\faTimesCircle}] Most complex implementation
    \item[\textcolor{dangerRed}{\faTimesCircle}] Requires careful stream depth tuning to avoid deadlock
\end{itemize}
\end{versionbox}

\newpage

\section{HLS Synthesis Results}

\begin{mytitledbox}{Vitis HLS Synthesis Comparison (256×256 Image)}

\begin{table}[H]
    \centering
    \caption{Latency and resource utilization comparison across versions.}
    \label{tab:hls_comparison}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Target Clock Period (ns) & 10.00 & 10.00 & 10.00 \\
        Estimated Clock (ns) & \textbf{7.30} & \textbf{7.30} & \textbf{7.30} \\
        \rowcolor{lightBlueBg!55} Latency (cycles) & \textbf{67632} & \textbf{3104} & \textbf{1048} \\
        Execution Time ($\mu$s) & \textbf{676.32} & \textbf{31.04} & \textbf{10.48} \\
        \midrule[0.8pt]
        \multicolumn{4}{c}{\textbf{Resource Utilization}} \\
        \midrule[0.8pt]
        DSP48E & \textbf{18} & \textbf{0} & \textbf{0} \\
        \rowcolor{lightBlueBg!55} BRAM\_18K & \textbf{256} & \textbf{30} & \textbf{0} \\
        Flip-Flops (FF) & \textbf{21841} & \textbf{19876} & \textbf{22975} \\
        \rowcolor{lightBlueBg!55} LUTs & \textbf{54593} & \textbf{38816} & \textbf{40869} \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\subsection{Loop-Level Latency Breakdown}

The Vitis HLS Performance \& Resource Estimates provide detailed loop-level latency analysis, revealing the bottlenecks in each implementation.

\begin{table}[H]
    \centering
    \caption{V1 loop-level breakdown: Sequential three-stage pipeline.}
    \label{tab:v1_breakdown}
    
    \begin{tabular}{@{}l r r@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Module / Loop}} & \textbf{\textcolor{primaryBlue}{Latency (cycles)}} & \textbf{\textcolor{primaryBlue}{\% of Total}} \\
        \midrule[0.8pt]
        \texttt{IMAGE\_DIFF\_POSTERIZE} (Top) & \textbf{67,632} & 100\% \\
        \midrule
        \quad \texttt{Pipeline\_Posterize\_Main\_Loop} & 1,027 & 1.5\% \\
        \rowcolor{lightBlueBg!55} \quad \texttt{Pipeline\_Filter\_Row\_Filter\_Col} & \textbf{65,551} & \textbf{97.0\%} \\
        \quad \texttt{Pipeline\_Pack\_Main\_Loop} & 1,027 & 1.5\% \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\begin{solutionbox}
{\color{dangerRed}\faExclamationTriangle}\hspace{2mm}\textbf{V1 Bottleneck Analysis:}

The filter stage (\texttt{Pipeline\_Filter\_Row\_Filter\_Col}) accounts for \highlight{97\%} of total latency. This is because:
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1mm]
    \item The 2D array access pattern with row-by-row processing creates dependencies
    \item Despite array partitioning, the nested loop structure limits parallelism
    \item Each row requires accessing three rows of the 2D buffer for convolution
\end{itemize}
\end{solutionbox}

\begin{table}[H]
    \centering
    \caption{V2 loop-level breakdown: Sequential with line buffer optimization.}
    \label{tab:v2_breakdown}
    
    \begin{tabular}{@{}l r r@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Module / Loop}} & \textbf{\textcolor{primaryBlue}{Latency (cycles)}} & \textbf{\textcolor{primaryBlue}{\% of Total}} \\
        \midrule[0.8pt]
        \texttt{IMAGE\_DIFF\_POSTERIZE} (Top) & \textbf{3,104} & 100\% \\
        \midrule
        \quad \texttt{Pipeline\_Posterize\_Loop} & 1,027 & 33.2\% \\
        \rowcolor{lightBlueBg!55} \quad \texttt{Pipeline\_Filter\_Loop} & 1,042 & 33.6\% \\
        \quad \texttt{Pipeline\_Write\_Loop} & 1,027 & 33.2\% \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\begin{solutionbox}
{\color{successGreen}\faLightbulb}\hspace{2mm}\textbf{V2 Optimization Strategy:}

By switching to line buffers and a sliding window approach, V2 achieves:
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1mm]
    \item \highlight{63× faster} filter stage (1,032 vs 65,551 cycles)
    \item Balanced stage latencies: Posterize (1,027), Filter (1,032), Write (1,027)
    \item The line buffer stores only 2 rows instead of the full frame
\end{itemize}
\vspace{2mm}
{\small\textcolor{textMuted}{\faInfoCircle\hspace{2mm}However, stages still execute \textbf{sequentially}, so total latency = $\sum$ stage latencies.}}
\end{solutionbox}

\begin{table}[H]
    \centering
    \caption{V3 module-level breakdown: Dataflow streaming architecture.}
    \label{tab:v3_breakdown}
    
    \begin{tabular}{@{}l r@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Module / Function}} & \textbf{\textcolor{primaryBlue}{Latency (cycles)}} \\
        \midrule[0.8pt]
        \texttt{IMAGE\_DIFF\_POSTERIZE} (Top) & \textbf{1,049} \\
        \midrule
        \quad \texttt{entry\_proc} & 0 \\
        \quad \texttt{compute\_diff\_wide} & 1,035 \\
        \rowcolor{lightBlueBg!55} \quad \texttt{apply\_filter\_wide} & \textbf{1,042} \\
        \quad \texttt{write\_result\_wide} & 1,035 \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\begin{solutionbox}
{\color{secondaryTeal}\faBolt}\hspace{2mm}\textbf{V3 Dataflow Parallelism:}

With \texttt{\#pragma HLS DATAFLOW}, all three functions execute \textbf{concurrently}. The total latency equals the \textbf{maximum} stage latency (1,042 cycles for \texttt{apply\_filter\_wide}) plus minimal overhead, achieving \highlight{1,049 cycles}---approaching the theoretical minimum of 1,024 cycles for a 256×256 image with 64 pixels/cycle throughput.
\end{solutionbox}

\subsection{Analysis}

\begin{solutionbox}
{\color{accentBlue}\faTachometerAlt}\hspace{2mm}\textbf{Performance Analysis:}
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1.5mm]
    \item \textbf{V1} uses full-frame 2D buffers with array partitioning for parallel access. The filter stage iterates row-by-row with direct neighbor access.
    \item \textbf{V2} optimizes memory storage by keeping data in 512-bit format but uses sequential stage execution.
    \item \textbf{V3} achieves the lowest latency through dataflow parallelism, allowing all three stages to execute concurrently on different data chunks.
\end{itemize}

\vspace{3mm}
{\color{purpleAccent}\faMemory}\hspace{2mm}\textbf{Resource Trade-offs:}
\begin{itemize}[label=\textcolor{purpleAccent}{\faAngleRight}, leftmargin=5mm, itemsep=1.5mm]
    \item V1 and V2 require more BRAM for intermediate storage
    \item V3 uses streams with depth=16, minimizing buffering requirements
    \item All versions unroll the 64-pixel inner loop, resulting in similar LUT usage
\end{itemize}
\end{solutionbox}


\section{Vitis IDE Execution Results}

The following results are obtained from running the accelerator on actual FPGA hardware using Vitis IDE.

\subsection{Kernel Execution Statistics}

\begin{mytitledbox}{Kernels \& Compute Units $\rightarrow$ Kernel Execution}

\begin{table}[H]
    \centering
    \caption{Kernel execution metrics from Vitis IDE.}
    \label{tab:kernel_exec}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Kernel Name & IMAGE\_DIFF & IMAGE\_DIFF & IMAGE\_DIFF \\
        \rowcolor{lightBlueBg!55} Compute Units & 1 & 1 & 1 \\
        Execution Time ($\mu$s) & \textbf{XXX.XX} & \textbf{XXX.XX} & \textbf{17} \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\subsection{Kernel Data Transfers}

\begin{mytitledbox}{Kernel Data Transfers $\rightarrow$ Top Kernel Data Transfer}

\begin{table}[H]
    \centering
    \caption{Top kernel data transfer statistics.}
    \label{tab:kernel_transfers}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Total Transfers & \textbf{XXX} & \textbf{XXX} & \textbf{64} \\
        \rowcolor{lightBlueBg!55} Transfer Rate (MB/s) & \textbf{XXXX.XX} & \textbf{XXXX.XX} & \textbf{8868.2} \\
        Avg Transfer Size (Bytes) & \textbf{XX.XX} & \textbf{XX.XX} & \textbf{1024} \\
        \rowcolor{lightBlueBg!55} Link Utilization (\%) & \textbf{XX.XX} & \textbf{XX.XX} & \textbf{25} \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\subsubsection{Understanding Kernel Transfer Metrics}

\begin{solutionbox}
{\color{accentBlue}\faDatabase}\hspace{2mm}\textbf{AXI Burst Coalescing:}

The \textbf{Average Transfer Size of 1024 bytes} is achieved through \textbf{AXI burst coalescing}. Although the kernel uses 512-bit (64-byte) memory ports via \texttt{uint512\_t}, the AXI infrastructure groups sequential accesses into larger bursts:

\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1mm]
    \item Each memory access moves 64 bytes (512 bits $\div$ 8)
    \item Sequential, pipelined accesses with II=1 are coalesced
    \item Memory controller issues \textbf{burst length 16} transactions
    \item Each burst: $16 \times 64 = \mathbf{1024}$ \textbf{bytes}
\end{itemize}

\vspace{2mm}
{\color{purpleAccent}\faBolt}\hspace{2mm}\textbf{Total Transfers = 64:}

\begin{tabular}{@{}ll@{}}
Total 512-bit chunks: & TOTAL\_CHUNKS = $4 \times 256 = 1024$ chunks \\
Chunks per burst: & 16 (AXI burst coalescing) \\
\textbf{Bursts per buffer:} & $1024 \div 16 = \mathbf{64}$ bursts \\
\end{tabular}
\end{solutionbox}

\begin{solutionbox}
{\color{warningOrange}\faExclamationCircle}\hspace{2mm}\textbf{Transfer Efficiency = 25\%:}

Vitis calculates transfer efficiency using this formula:
$$\text{Efficiency} = \frac{\text{Average Bytes}}{\min(\text{Memory Byte Width} \times 256, 4096)}$$

For V3:
\begin{itemize}[leftmargin=5mm, itemsep=1mm]
    \item Memory Byte Width: $512 \div 8 = 64$ bytes
    \item Memory Width $\times$ 256: $64 \times 256 = 16384$ bytes
    \item $\min(16384, 4096) = \mathbf{4096}$ bytes (DDR page size limit)
    \item Efficiency: $1024 \div 4096 = \mathbf{25\%}$
\end{itemize}

\end{solutionbox}

\subsection{Host Data Transfers}

\begin{mytitledbox}{Host Data Transfer $\rightarrow$ Host Transfer}

\begin{table}[H]
    \centering
    \caption{Host-to-device and device-to-host transfer statistics.}
    \label{tab:host_transfers}
    
    \begin{tabular}{@{}l c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Metric}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        \multicolumn{4}{c}{\textbf{Host to Device}} \\
        \midrule[0.8pt]
        Transfer Count & \textbf{XXX} & \textbf{XXX} & \textbf{1} \\
        \rowcolor{lightBlueBg!55} Transfer Rate (MB/s) & \textbf{XXXX.XX} & \textbf{XXXX.XX} & \textbf{3.153} \\
        Avg Size (Bytes) & \textbf{XX.XX} & \textbf{XX.XX} & \textbf{131072} \\
        \midrule[0.8pt]
        \multicolumn{4}{c}{\textbf{Device to Host}} \\
        \midrule[0.8pt]
        Transfer Count & \textbf{XXX} & \textbf{XXX} & \textbf{1} \\
        \rowcolor{lightBlueBg!55} Transfer Rate (MB/s) & \textbf{XXXX.XX} & \textbf{XXXX.XX} & \textbf{1.422} \\
        Avg Size (Bytes) & \textbf{XX.XX} & \textbf{XX.XX} & \textbf{65536} \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\subsubsection{Understanding Host vs Kernel Transfer Rate Difference}

\begin{solutionbox}
{\color{dangerRed}\faExclamationTriangle}\hspace{2mm}\textbf{Dramatic Rate Difference:}

\begin{tabular}{@{}lrl@{}}
\textbf{Host $\leftrightarrow$ Device:} & $\sim$3.1 MB/s & (PCIe path) \\
\textbf{Kernel $\leftrightarrow$ DDR:} & $\sim$8868 MB/s & (On-chip AXI path) \\
\textbf{Ratio:} & $\sim$2800$\times$ & slower for host transfers \\
\end{tabular}

\vspace{3mm}
{\color{accentBlue}\faQuestionCircle}\hspace{2mm}\textbf{Why Such a Large Difference?}

\begin{enumerate}[label=\textcolor{accentBlue}{\arabic*.}, itemsep=2mm, leftmargin=6mm]
    \item \textbf{Hardware Emulation vs Real Hardware:} The $\sim$3 MB/s rate is characteristic of \texttt{hw\_emu} mode, where PCIe transfers are \textit{simulated in software}. On real FPGA hardware, PCIe Gen3 x16 achieves 8--12 GB/s.
    
    \item \textbf{Different Memory Paths:}
    \begin{itemize}[label=\textcolor{purpleAccent}{$\bullet$}, leftmargin=4mm]
        \item \textbf{Kernel $\leftrightarrow$ DDR:} Uses on-chip 512-bit wide AXI bus directly connected to DDR memory controller
        \item \textbf{Host $\leftrightarrow$ Device:} Traverses PCIe bus with DMA engines and multiple protocol layers
    \end{itemize}
    
    \item \textbf{Small Transfer Size Overhead:} With only 128 KB write and 64 KB read, fixed latency overhead (DMA descriptor setup, address negotiation) dominates the transfer time. Larger data sizes amortize this overhead.
    
    \item \textbf{No Transfer/Compute Overlap:} The host code uses sequential, blocking operations without double-buffering or pipelining.
\end{enumerate}
\end{solutionbox}

\begin{solutionbox}
{\color{successGreen}\faCheck}\hspace{2mm}\textbf{Host Transfer Size Breakdown:}

\begin{tabular}{@{}lr@{}}
\textbf{Host $\rightarrow$ Device (WRITE):} & \textbf{131072 Bytes} \\
\quad Buffer A (input image 1): & 65536 Bytes \\
\quad Buffer B (input image 2): & 65536 Bytes \\
\\
\textbf{Device $\rightarrow$ Host (READ):} & \textbf{65536 Bytes} \\
\quad Buffer C (output image): & 65536 Bytes \\
\end{tabular}

\vspace{2mm}
{\small\textcolor{textMuted}{\faInfoCircle\hspace{2mm}Buffer size = TOTAL\_CHUNKS $\times$ PIXELS\_PER\_CHUNK = $1024 \times 64 = 65536$B}}
\end{solutionbox}

\section{Performance Comparison Summary}

\begin{mytitledbox}{Overall Performance Comparison}

\begin{table}[H]
    \centering
    \caption{Summary comparison of all three implementations.}
    \label{tab:summary}
    
    \begin{tabular}{@{}p{0.35\textwidth} c c c@{}}
        \toprule[1.5pt]
        \textbf{\textcolor{primaryBlue}{Characteristic}} & \textbf{\textcolor{primaryBlue}{V1}} & \textbf{\textcolor{primaryBlue}{V2}} & \textbf{\textcolor{primaryBlue}{V3}} \\
        \midrule[0.8pt]
        Architecture & Sequential & Sequential & Dataflow \\
        \rowcolor{lightBlueBg!55} Buffer Type & 2D Arrays & 512-bit Chunks & Streams \\
        Filter Implementation & Direct 2D & Line Buffer & Line Buffer \\
        \rowcolor{lightBlueBg!55} Stage Parallelism & None & None & Full Overlap \\
        \midrule[0.8pt]
        HLS Latency (cycles) & \textbf{XXXXX} & \textbf{XXXXX} & \textbf{XXXXX} \\
        \rowcolor{lightBlueBg!55} FPGA Exec Time ($\mu$s) & \textbf{XXX.XX} & \textbf{XXX.XX} & \textbf{XXX.XX} \\
        BRAM Usage & Low & Medium & Low \\
        \rowcolor{lightBlueBg!55} Implementation Complexity & Simple & Medium & High \\
        \bottomrule[1.5pt]
    \end{tabular}
\end{table}

\end{mytitledbox}

\subsection{Speed-up Calculation}

\begin{solutionbox}
\hspace{2mm}\textbf{V3 vs V1 Speed-up:}
$$ \text{Speedup} = \frac{\text{Latency}_{V1}}{\text{Latency}_{V3}} = \frac{XXXXX}{XXXXX} \approx \mathbf{X.XX \times} $$

\hspace{2mm}\textbf{V3 vs V2 Speed-up:}
$$ \text{Speedup} = \frac{\text{Latency}_{V2}}{\text{Latency}_{V3}} = \frac{XXXXX}{XXXXX} \approx \mathbf{X.XX \times} $$
\end{solutionbox}

\subsection{Theoretical vs. Actual Performance}

\begin{solutionbox}
{\color{purpleAccent}\faBalanceScale}\hspace{2mm}\textbf{HLS Estimate vs. FPGA Execution (V3):}

\begin{tabular}{@{}ll@{}}
\textbf{HLS Estimated Latency:} & 1,048 cycles $\times$ 10 ns = \textbf{10.48 $\mu$s} \\
\textbf{Actual FPGA Execution:} & \textbf{17 $\mu$s} \\
\textbf{Overhead:} & $\sim$62\% additional time \\
\end{tabular}

\vspace{3mm}
{\color{accentBlue}\faQuestionCircle}\hspace{2mm}\textbf{Why the Difference?}
\begin{itemize}[label=\textcolor{accentBlue}{\faAngleRight}, leftmargin=5mm, itemsep=1mm]
    \item \textbf{Memory Access Latency:} HLS estimates assume ideal memory conditions. Real DDR access introduces variable latency for burst reads/writes.
    \item \textbf{Kernel Launch Overhead:} OpenCL runtime adds setup time for command queue dispatch and synchronization.
    \item \textbf{Clock Domain Crossing:} Data transfers between PL (programmable logic) and DDR traverse clock domains, adding cycles.
    \item \textbf{AXI Protocol Overhead:} Address negotiation and burst setup in AXI transactions not fully modeled by HLS.
\end{itemize}

\vspace{2mm}
{\small\textcolor{textMuted}{\faInfoCircle\hspace{2mm}For small images (256$\times$256), these fixed overheads dominate. As image size increases, the ratio of compute to overhead improves, and actual performance approaches HLS estimates.}}
\end{solutionbox}

\section{Conclusion}

\begin{tcolorbox}[mybox]
\faFlagCheckered\hspace{2mm}This laboratory exercise explored three architectural approaches for implementing an image processing accelerator with difference, posterization, and sharpening operations:

\begin{itemize}[leftmargin=5mm, itemsep=3mm]
    \item \textbf{V1 (Sequential + 2D Buffers):} Simplest implementation with straightforward 2D array access for the filter stage. Trades off memory for simplicity.
    
    \item \textbf{V2 (Sequential + Line Buffers):} More memory-efficient filter implementation using sliding window on 512-bit chunks, but still sequential execution.
    
    \item \textbf{V3 (Dataflow + Streams):} Achieves maximum performance through pipeline parallelism with HLS streams. All stages execute concurrently, approaching theoretical minimum latency.
\end{itemize}

\vspace{3mm}
\textcolor{textMuted}{\faLightbulb}\hspace{2mm}\textit{The results demonstrate the trade-offs between implementation complexity, resource utilization, and performance. The dataflow architecture (V3) provides the best performance but requires careful design of stream depths and stage balancing.}
\end{tcolorbox}

\vspace{5mm}
\noindent\textcolor{textMuted}{\faBook\hspace{2mm}\textbf{Reference:}} For more details on interpreting the Vitis profile summary, see the official AMD documentation: \href{https://docs.amd.com/r/2022.1-English/ug1393-vitis-application-acceleration/Interpreting-the-Profile-Summary}{Interpreting the Profile Summary}.

\end{document}
